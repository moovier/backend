{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NNiewCdFMZlx",
    "ExecuteTime": {
     "end_time": "2023-11-26T10:50:09.759076238Z",
     "start_time": "2023-11-26T10:50:07.584204333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 11:50:08.174124: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 11:50:08.211758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-26 11:50:08.211801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-26 11:50:08.213002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-26 11:50:08.219242: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 11:50:08.219763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-26 11:50:09.050203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "TRAINING_SPLIT_RATIO = 0.9\n",
    "EMBEDDING_SIZE = 50\n",
    "TOP_K = 10"
   ],
   "metadata": {
    "id": "SDAnQCmDXiKn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "movielens_dataset_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    fname=\"ml-latest-small.zip\",\n",
    "    origin=movielens_dataset_url,\n",
    "    extract=True,\n",
    "    archive_format=\"zip\")\n",
    "\n",
    "movielens_dir = Path(movielens_zipped_file).parent / \"ml-latest-small\""
   ],
   "metadata": {
    "id": "6C-1ZtJBNJ8A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ratings_file = movielens_dir / \"ratings.csv\"\n",
    "rating_df = pd.read_csv(ratings_file)\n",
    "\n",
    "user_id = rating_df.userId.unique().tolist()\n",
    "user_to_index = { user: index for index, user in enumerate(user_id) }\n",
    "index_to_user = { index: user for index, user in enumerate(user_id) }\n",
    "\n",
    "movie_id = rating_df.movieId.unique().tolist()\n",
    "movie_to_index = { movie: index for index, movie in enumerate(movie_id) }\n",
    "index_to_movie = { index: movie for index, movie in enumerate(movie_id) }\n",
    "\n",
    "rating_df[\"user\"]   = rating_df.userId.map(user_to_index)\n",
    "rating_df[\"movie\"]  = rating_df.movieId.map(index_to_movie)\n",
    "rating_df.rating    = rating_df.rating.values.astype(np.float32)\n",
    "\n",
    "num_users, num_movies  = len(user_id), len(movie_id)\n",
    "min_rating, max_rating = min(rating_df.rating), max(rating_df.rating)\n",
    "\n",
    "print(f\"num_users:{num_users}, num_movies:{num_movies}, min_rating:{min_rating}, max_rating:{max_rating}\")"
   ],
   "metadata": {
    "id": "wFaf31f7NJVk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "normalization_func = lambda x: (x - min_rating) / (max_rating - min_rating)\n",
    "\n",
    "df = rating_df.sample(frac=1, random_state=42)\n",
    "x  = df[[\"user\", \"movie\"]].values\n",
    "y  = df.rating.apply(normalization_func).values\n",
    "\n",
    "train_split = int(TRAINING_SPLIT_RATIO * df.shape[0])\n",
    "\n",
    "x_train = x[:train_split]\n",
    "x_val   = x[train_split:]\n",
    "y_train = y[:train_split]\n",
    "y_val   = y[train_split:]"
   ],
   "metadata": {
    "id": "0CqZF17_VnXP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_bias = layers.Embedding(input_dim=num_users, output_dim=1)\n",
    "        self.movie_bias = layers.Embedding(input_dim=num_movies, output_dim=1)\n",
    "\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            input_dim=num_movies,\n",
    "            output_dim=embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        return tf.nn.sigmoid(x)\n",
    "\n",
    "\n",
    "model = RecommenderNet(\n",
    "    num_users,\n",
    "    num_movies,\n",
    "    EMBEDDING_SIZE,\n",
    "    name=\"recommender-net\"\n",
    "  )\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    ")"
   ],
   "metadata": {
    "id": "50MJCpcPX88r"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ],
   "metadata": {
    "id": "12cNdPGDbpDb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "val_loss = history.history[\"val_loss\"]\n",
    "loss = history.history[\"loss\"]\n",
    "\n",
    "plt.title(f\"{model.name} loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "TyTzQUvIdiYZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
    "\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched = df[df.userId == user_id]\n",
    "\n",
    "movies_not_watched = ~movie_df.movieId.isin(movies_watched.movieId.values)\n",
    "movies_not_watched = movie_df[movies_not_watched].movieId\n",
    "movies_not_watched = set(movies_not_watched) & set(movie_to_index.keys())\n",
    "movies_not_watched = list(movies_not_watched)\n",
    "movies_not_watched = [[movie_to_index.get(movie)] for movie in movies_not_watched]\n",
    "\n",
    "user_encoder = user_to_index.get(user_id)\n",
    "\n",
    "inputs = ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    "inputs = np.hstack(inputs)\n",
    "\n",
    "ratings = model.predict(inputs)\n",
    "ratings = ratings.flatten()\n",
    "ratings = ratings.argsort()[-TOP_K:][::-1]\n",
    "\n",
    "recommended_movie_ids = [\n",
    "    index_to_movie.get(movies_not_watched[rating][0]) for rating in ratings\n",
    "]\n",
    "\n",
    "print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "print(\"====\" * 9)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieId.values\n",
    ")\n",
    "\n",
    "movie_df_rows = movie_df[movie_df.movieId.isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title, \":\", row.genres)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df.movieId.isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, \":\", row.genres)"
   ],
   "metadata": {
    "id": "RpsVXfkJeXpx"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
